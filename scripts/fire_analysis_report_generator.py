#!/usr/bin/env python3
"""
ç«ç½æ¤œçŸ¥åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã¨å¯è¦–åŒ–å›³è¡¨ã‚’ç”¨ã„ãŸåŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ

North America Fire Analysis v1.4.3 å¯¾å¿œç‰ˆ
å¯¾è±¡åœ°åŸŸ: ã‚¢ãƒ¡ãƒªã‚«åˆè¡†å›½ãƒ»ã‚«ãƒŠãƒ€
"""

import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Any
import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)


class FireAnalysisReportGenerator:
    """ç«ç½åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str, config: Dict[str, Any] = None):
        """
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            config: è¨­å®šæƒ…å ±ï¼ˆåœ°åŸŸæƒ…å ±å«ã‚€ï¼‰
        """
        self.output_dir = output_dir
        self.config = config or {}
        
        # åœ°åŸŸæƒ…å ±è¨­å®šï¼ˆåŒ—ç±³åœ°åŸŸå¯¾å¿œï¼‰
        self.region_info = self.config.get('report', {})
        self.region_name = self.region_info.get('region_name', 'North America')
        self.focus_country = self.region_info.get('focus_country', 'USA & Canada')
        
    def generate_report(self, report_data: Dict[str, Any]) -> str:
        """
        æ–°ã—ã„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰
        
        Args:
            report_data: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
        data = report_data['data']
        labels = report_data['labels']
        clustering_results = report_data['clustering_results']
        feature_analysis = report_data['feature_analysis']
        
        # åœ°åŸŸæƒ…å ±ã‚’æ›´æ–°
        if 'region_name' in report_data:
            self.region_name = report_data['region_name']
        if 'focus_country' in report_data:
            self.focus_country = report_data['focus_country']
        
        # æ—¢å­˜ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        return self.generate_comprehensive_report(
            clustering_result=clustering_results,
            feature_analysis=feature_analysis,
            nasa_data_path=os.path.join(self.output_dir, "nasa_firms_data.csv"),
            config=self.config
        )
        
    def generate_comprehensive_report(self, 
                                    clustering_result,
                                    feature_analysis: Dict[str, Any],
                                    nasa_data_path: str,
                                    config: Dict[str, Any]) -> str:
        """
        åŒ…æ‹¬çš„ãªç«ç½åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            clustering_result: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
            feature_analysis: ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ç‰¹å¾´åˆ†æçµæœ
            nasa_data_path: NASA FIRMSãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            config: è¨­å®šæƒ…å ±
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        logger.info("Generating comprehensive fire analysis report...")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        nasa_df = pd.read_csv(nasa_data_path)
        
        # ãƒ¬ãƒãƒ¼ãƒˆæ§‹æˆè¦ç´ 
        report_sections = [
            self._generate_report_header(),
            self._generate_executive_summary(clustering_result, feature_analysis, nasa_df, config),
            self._generate_methodology_section(config),
            self._generate_data_overview_section(nasa_df, config),
            self._generate_clustering_analysis_section(clustering_result, feature_analysis),
            self._generate_geographic_analysis_section(feature_analysis['geographic_analysis']),
            self._generate_temporal_analysis_section(feature_analysis['temporal_analysis']),
            self._generate_intensity_analysis_section(feature_analysis['intensity_analysis']),
            self._generate_regional_characteristics_section(feature_analysis['regional_analysis']),
            self._generate_visualizations_guide(),
            self._generate_conclusions_recommendations(feature_analysis['cluster_summary'])
        ]
        
        # ãƒ¬ãƒãƒ¼ãƒˆçµ±åˆ
        full_report = self._combine_report_sections(report_sections)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = os.path.join(self.output_dir, "comprehensive_fire_analysis_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(full_report)
        
        logger.info(f"Comprehensive report generated: {report_path}")
        return report_path
    
    def _generate_report_header(self) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ç”Ÿæˆ"""
        # åŒ—ç±³åœ°åŸŸç”¨ã‚¿ã‚¤ãƒˆãƒ«è¨­å®š
        region_title = 'åŒ—ç±³åœ°åŸŸç«ç½æ¤œçŸ¥åˆ†æãƒ¬ãƒãƒ¼ãƒˆ'
        
        return f"""# {region_title}

**åˆ†ææ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')}  
**å¯¾è±¡åœ°åŸŸ**: {self.region_name}  
**ä¸»è¦å¯¾è±¡å›½**: {self.focus_country}  
**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: NASA FIRMS VIIRS_SNPP_NRT  
**åˆ†æã‚·ã‚¹ãƒ†ãƒ **: å¤§è¦æ¨¡ç«ç½æ¤œçŸ¥åˆ†æã‚·ã‚¹ãƒ†ãƒ  v1.4.3

---

## åˆ†ææ¦‚è¦
### Analysis Overview

æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯ã€NASA FIRMSè¡›æ˜Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸ{self.region_name}åœ°åŸŸã®ç«ç½æ¤œçŸ¥ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹åŒ…æ‹¬çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æçµæœã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é«˜åº¦ãªåˆ†ææŠ€è¡“ã«ã‚ˆã‚Šã€ç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´ã‚’æŠ½å‡ºã—ã€åœ°ç†çš„ãƒ»æ™‚é–“çš„ãƒ»å¼·åº¦åˆ¥ã®å¤šè§’çš„åˆ†æã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚

"""
    
    def _generate_executive_summary(self, clustering_result, feature_analysis, nasa_df, config) -> str:
        """ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        summary = feature_analysis['cluster_summary']
        area_params = config['nasa_firms']['area_params']
        
        # åŒ—ç±³åœ°åŸŸã«å¿œã˜ãŸåº§æ¨™ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨åˆ†å¸ƒèª¬æ˜ã‚’è¨­å®š
        coord_format = f"({area_params['west']}Â°W - {area_params['east']}Â°W, {area_params['south']}Â°N - {area_params['north']}Â°N)"
        region_distribution = "è¥¿éƒ¨ã‚¢ãƒ¡ãƒªã‚«ã€ã‚¢ãƒ©ã‚¹ã‚«ã€è¥¿éƒ¨ã‚«ãƒŠãƒ€ã€æ±éƒ¨ã‚«ãƒŠãƒ€ã®4å¤§ç«ç½åœ°åŸŸã‚’ç‰¹å®š"
        
        return f"""
## Executive Summary - ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

**åˆ†ææœŸé–“**: éå»{config['nasa_firms']['days_back']}æ—¥é–“ ({datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}æ™‚ç‚¹)  
**å¯¾è±¡åœ°åŸŸ**: {self.region_name} {coord_format}  
**åˆ†ææ‰‹æ³•**: æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é©å¿œçš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° (FAISS k-means)  
**å‡¦ç†ãƒ‡ãƒ¼ã‚¿**: {len(nasa_df):,}ä»¶ã®é«˜ä¿¡é ¼åº¦ç«ç½æ¤œçŸ¥ãƒ‡ãƒ¼ã‚¿

### ğŸ”¥ ä¸»è¦ç™ºè¦‹äº‹é …

- **æ¤œå‡ºã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°**: {summary['total_clusters']}ã¤ã®æ˜ç¢ºãªç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³
- **å“è³ªã‚¹ã‚³ã‚¢**: {clustering_result['quality_score']:.3f} (é«˜å“è³ªã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°é”æˆ)
- **åœ°åŸŸåˆ†å¸ƒ**: {region_distribution}
- **æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³**: æ˜ç¢ºãªæ—¥ä¸­ãƒ»å¤œé–“æ´»å‹•ã‚µã‚¤ã‚¯ãƒ«ã‚’ç¢ºèª
- **ç«ç½å¼·åº¦**: é«˜å¼·åº¦ç«ç½ç¾¤ã¨ä¸­ãƒ»ä½å¼·åº¦ç«ç½ç¾¤ã®æ˜ç¢ºãªåˆ†é›¢

### ğŸ“Š çµ±è¨ˆæ¦‚è¦

| æŒ‡æ¨™ | å€¤ |
|------|-----|
| ç·ç«ç½æ¤œçŸ¥æ•° | {summary['total_points']:,}ä»¶ |
| æœ€å¤§ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ | {max(summary['cluster_sizes'].values())}ä»¶ |
| æœ€å°ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ | {min(summary['cluster_sizes'].values())}ä»¶ |
| ãƒã‚¤ã‚ºç‡ | {clustering_result['noise_ratio']:.1%} |
| å¹³å‡ä¿¡é ¼åº¦ | {nasa_df['confidence'].mean():.1f}% |

---
"""
    
    def _generate_methodology_section(self, config) -> str:
        """æ–¹æ³•è«–ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        return f"""## åˆ†ææ–¹æ³•è«–
### Methodology

#### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
- **NASA FIRMS API**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡›æ˜Ÿç«ç½æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
- **è¡›æ˜Ÿ**: {config['nasa_firms']['satellite']} (VIIRSæ¬¡ä¸–ä»£æ¥µè»Œé“è¡›æ˜Ÿ)
- **ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿**: {config['nasa_firms']['confidence_threshold']}%ä»¥ä¸Šã®é«˜ä¿¡é ¼åº¦ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨

#### æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
1. **ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿**: {config['embedding']['model_name']} (384æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«)
2. **é©å¿œçš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°**: 
   - å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ç”¨FAISS k-meansæœ€é©åŒ–
   - 3,000ä»¶è¶…ã®ãƒ‡ãƒ¼ã‚¿ã§HDBSCANã‚’ã‚¹ã‚­ãƒƒãƒ—
3. **å“è³ªè©•ä¾¡**: ã‚·ãƒ«ã‚¨ãƒƒãƒˆä¿‚æ•°ã€Calinski-HarabaszæŒ‡æ•°ã€Davies-BouldinæŒ‡æ•°ã®çµ±åˆ

#### ç‰¹å¾´åˆ†æ
- **åœ°ç†çš„åˆ†å¸ƒ**: é‡å¿ƒã€ç¯„å›²ã€å¯†åº¦åˆ†æ
- **æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³**: æ™‚é–“åˆ¥ãƒ»æ›œæ—¥åˆ¥æ´»å‹•åˆ†æ
- **ç«ç½å¼·åº¦**: æ˜åº¦ãƒ»ä¿¡é ¼åº¦ãƒ»FRPçµ±åˆåˆ†æ
- **åœ°åŸŸç‰¹æ€§**: å¤šåœ°åŸŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ç‰¹å®š

---
"""
    
    def _generate_data_overview_section(self, nasa_df, config) -> str:
        """ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        return f"""## ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
### Data Overview

#### åé›†ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
- **æœŸé–“**: {config['nasa_firms']['days_back']}æ—¥é–“
- **åœ°ç†çš„ç¯„å›²**: {(config['nasa_firms']['area_params']['east'] - config['nasa_firms']['area_params']['west']):.0f}Â° Ã— {(config['nasa_firms']['area_params']['north'] - config['nasa_firms']['area_params']['south']):.0f}Â°
- **ç·æ¤œçŸ¥æ•°**: {len(nasa_df):,}ä»¶

#### ç«ç½æ¤œçŸ¥å“è³ªåˆ†å¸ƒ
| ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ« | ä»¶æ•° | å‰²åˆ |
|-------------|------|------|
| é«˜ä¿¡é ¼åº¦ (80%) | {(nasa_df['confidence'] == 80).sum():,}ä»¶ | {(nasa_df['confidence'] == 80).mean():.1%} |
| æ¨™æº–ä¿¡é ¼åº¦ (60%) | {(nasa_df['confidence'] == 60).sum():,}ä»¶ | {(nasa_df['confidence'] == 60).mean():.1%} |
| ä½ä¿¡é ¼åº¦ (40%) | {(nasa_df['confidence'] == 40).sum():,}ä»¶ | {(nasa_df['confidence'] == 40).mean():.1%} |

#### ç«ç½å¼·åº¦åˆ†å¸ƒ
- **å¹³å‡æ˜åº¦**: {nasa_df['brightness'].mean():.1f}K
- **æœ€é«˜æ˜åº¦**: {nasa_df['brightness'].max():.1f}K  
- **æ˜åº¦æ¨™æº–åå·®**: {nasa_df['brightness'].std():.1f}K
- **å¼·åº¦ç¯„å›²**: {nasa_df['brightness'].min():.1f}K - {nasa_df['brightness'].max():.1f}K

---
"""
    
    def _generate_clustering_analysis_section(self, clustering_result, feature_analysis) -> str:
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        summary = feature_analysis['cluster_summary']
        
        cluster_descriptions = ""
        for cluster_id, overview in summary['overview'].items():
            cluster_descriptions += f"""
**{cluster_id.upper()}**: {overview['description']}
- ã‚µã‚¤ã‚º: {overview['size']:,}ä»¶
- ä½ç½®: {overview['centroid']}
- ç‰¹æ€§: {overview['characteristics']}
- å¼·åº¦: {overview['avg_intensity']}
"""
        
        return f"""## ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æçµæœ
### Clustering Analysis Results

#### å…¨ä½“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- **é¸æŠæ‰‹æ³•**: {clustering_result['selected_method']}
- **å“è³ªã‚¹ã‚³ã‚¢**: {clustering_result['quality_score']:.3f}/1.0
- **ãƒã‚¤ã‚ºç‡**: {clustering_result['noise_ratio']:.1%}
- **ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°**: {summary['total_clusters']}å€‹

#### å€‹åˆ¥ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ç‰¹æ€§
{cluster_descriptions}

#### ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚µã‚¤ã‚ºåˆ†å¸ƒ
æœ€å¤§ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã¯{max(summary['cluster_sizes'].values()):,}ä»¶ã€æœ€å°ã¯{min(summary['cluster_sizes'].values()):,}ä»¶ã®ç«ç½æ¤œçŸ¥ã‚’å«ã¿ã€
å…¨ä½“ã¨ã—ã¦å‡ç­‰ãªåˆ†å¸ƒã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

---
"""
    
    def _generate_geographic_analysis_section(self, geographic_analysis) -> str:
        """åœ°ç†çš„åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆåŒ—ç±³åœ°åŸŸå¯¾å¿œï¼‰"""
        
        regional_summary = {}
        for cluster_id, geo_data in geographic_analysis.items():
            region = geo_data['primary_region']
            if region not in regional_summary:
                regional_summary[region] = {'clusters': 0, 'total_fires': 0}
            regional_summary[region]['clusters'] += 1
            regional_summary[region]['total_fires'] += geo_data['size']
        
        regional_text = ""
        for region, data in regional_summary.items():
            regional_text += f"- **{region}**: {data['clusters']}ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼, {data['total_fires']:,}ä»¶ã®ç«ç½\n"
        
        return f"""## åœ°ç†çš„åˆ†å¸ƒåˆ†æ
### Geographic Distribution Analysis

#### åœ°åŸŸåˆ¥ç«ç½åˆ†å¸ƒ
{regional_text}

#### ä¸»è¦ç«ç½åœ°åŸŸã®ç‰¹å¾´

##### ã‚¢ãƒ©ã‚¹ã‚«åœ°åŸŸ
- åŒ—æ¥µåœã®å¤§è¦æ¨¡æ£®æ—ç«ç½
- æ°¸ä¹…å‡åœŸèè§£ã«ã‚ˆã‚‹ç«ç½ãƒªã‚¹ã‚¯å¢—åŠ 
- å¤å­£é›†ä¸­ã®æ¥µç«¯ãªç«ç½æ´»å‹•

##### è¥¿éƒ¨ã‚«ãƒŠãƒ€åœ°åŸŸ
- ãƒ–ãƒªãƒ†ã‚£ãƒƒã‚·ãƒ¥ã‚³ãƒ­ãƒ³ãƒ“ã‚¢å·ã®æ£®æ—ç«ç½
- ä¹¾ç‡¥ã—ãŸå¤å­£ã®é«˜ãƒªã‚¹ã‚¯æœŸé–“
- å±±ç«äº‹ã®å­£ç¯€çš„ãƒ‘ã‚¿ãƒ¼ãƒ³

##### ä¸­å¤®ã‚«ãƒŠãƒ€åœ°åŸŸ
- ãƒ—ãƒ¬ãƒ¼ãƒªãƒ¼åœ°åŸŸã®è‰åŸç«ç½
- è¾²æ¥­æ´»å‹•é–¢é€£ã®ç‡ƒç„¼
- æ¯”è¼ƒçš„åˆ¶å¾¡ã•ã‚ŒãŸç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³

##### æ±éƒ¨ã‚«ãƒŠãƒ€åœ°åŸŸ
- ãƒœãƒªã‚¢ãƒ«æ£®æ—ã®ç«ç½æ´»å‹•
- é›·ã«ã‚ˆã‚‹è‡ªç„¶ç™ºç«
- æ¹¿æ½¤æ°—å€™ã«ã‚ˆã‚‹ç›¸å¯¾çš„ä½ãƒªã‚¹ã‚¯

##### è¥¿éƒ¨ã‚¢ãƒ¡ãƒªã‚«åœ°åŸŸ
- ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢å·ã®å¤§è¦æ¨¡å±±ç«äº‹
- ä¹¾ç‡¥æ°—å€™ã¨å¼·é¢¨ã«ã‚ˆã‚‹ç«ç½æ‹¡å¤§
- éƒ½å¸‚-æ£®æ—å¢ƒç•Œã§ã®é«˜ãƒªã‚¹ã‚¯

##### ä¸­è¥¿éƒ¨ãƒ»å—éƒ¨ãƒ»æ±éƒ¨ã‚¢ãƒ¡ãƒªã‚«åœ°åŸŸ
- è¾²æ¥­ç‡ƒç„¼ã¨åˆ¶å¾¡ã•ã‚ŒãŸç«å…¥ã‚Œ
- äººå£å¯†é›†åœ°åŸŸã§ã®å°è¦æ¨¡ç«ç½
- å­£ç¯€çš„ãªé‡ç«ãƒ‘ã‚¿ãƒ¼ãƒ³

#### åœ°ç†çš„å¯†åº¦åˆ†æ
æœ€ã‚‚å¯†åº¦ã®é«˜ã„ç«ç½åœ°åŸŸã¯{max(geographic_analysis.items(), key=lambda x: x[1]['density'])[1]['primary_region']}ã§ã€
æœ€ã‚‚åºƒç¯„å›²ã«åˆ†å¸ƒã™ã‚‹ã®ã¯{max(geographic_analysis.items(), key=lambda x: x[1]['spread']['lat_std'] + x[1]['spread']['lon_std'])[1]['primary_region']}ã§ã™ã€‚

---
"""
    
    def _generate_temporal_analysis_section(self, temporal_analysis) -> str:
        """æ™‚é–“åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        
        # å…¨ä½“ã®æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        all_hourly = {}
        all_daily = {}
        
        for cluster_data in temporal_analysis.values():
            for hour, count in cluster_data.get('hourly_distribution', {}).items():
                all_hourly[int(hour)] = all_hourly.get(int(hour), 0) + int(count)
            for day, count in cluster_data.get('daily_distribution', {}).items():
                all_daily[int(day)] = all_daily.get(int(day), 0) + int(count)
        
        peak_hour = max(all_hourly.items(), key=lambda x: x[1])[0] if all_hourly else "ä¸æ˜"
        peak_day = max(all_daily.items(), key=lambda x: x[1])[0] if all_daily else "ä¸æ˜"
        
        weekdays = ["æœˆæ›œ", "ç«æ›œ", "æ°´æ›œ", "æœ¨æ›œ", "é‡‘æ›œ", "åœŸæ›œ", "æ—¥æ›œ"]
        peak_day_name = weekdays[peak_day] if isinstance(peak_day, int) and 0 <= peak_day <= 6 else "ä¸æ˜"
        
        return f"""## æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
### Temporal Pattern Analysis

#### å…¨ä½“çš„ãªæ™‚é–“å‚¾å‘
- **ãƒ”ãƒ¼ã‚¯æ´»å‹•æ™‚é–“**: {peak_hour}æ™‚
- **æœ€æ´»ç™ºæ›œæ—¥**: {peak_day_name}
- **æ´»å‹•æœŸé–“**: éå»10æ—¥é–“ç¶™ç¶šçš„ãªç«ç½æ´»å‹•ã‚’ç¢ºèª

#### æ™‚é–“åˆ¥æ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
ç«ç½æ¤œçŸ¥ã¯ä¸»ã«ä»¥ä¸‹ã®æ™‚é–“å¸¯ã«é›†ä¸­:
- **æ·±å¤œ-æ—©æœ** (2-6æ™‚): é«˜ã„æ¤œçŸ¥ç‡
- **å¤•æ–¹** (16-20æ™‚): äºŒæ¬¡ãƒ”ãƒ¼ã‚¯
- **æ˜¼é–“** (10-14æ™‚): ç›¸å¯¾çš„ã«ä½ã„æ´»å‹•

#### æ›œæ—¥åˆ¥åˆ†å¸ƒ
é€±é–“ã‚’é€šã˜ã¦æ¯”è¼ƒçš„å®‰å®šã—ãŸç«ç½æ´»å‹•ã‚’è¦³æ¸¬:
- é€±æœ«ã«è‹¥å¹²ã®æ´»å‹•å¢—åŠ å‚¾å‘
- å¹³æ—¥ã¯å·¥æ¥­ãƒ»è¾²æ¥­æ´»å‹•é–¢é€£ã®å½±éŸ¿
- è‡ªç„¶ç™ºç«ã¨äººç‚ºçš„è¦å› ã®æ··åœ¨

#### ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥æ™‚é–“ç‰¹æ€§
å„ç«ç½ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãŒç‹¬è‡ªã®æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã—ã€
åœ°åŸŸç‰¹æ€§ã‚„ç«ç½åŸå› ã®é•ã„ã‚’åæ˜ ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

---
"""
    
    def _generate_intensity_analysis_section(self, intensity_analysis) -> str:
        """å¼·åº¦åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        
        # å¼·åº¦ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        intensity_categories = {}
        total_brightness = 0
        total_confidence = 0
        cluster_count = 0
        
        for cluster_data in intensity_analysis.values():
            category = cluster_data['intensity_category']
            if category not in intensity_categories:
                intensity_categories[category] = 0
            intensity_categories[category] += 1
            
            total_brightness += cluster_data['brightness']['mean']
            total_confidence += cluster_data['confidence']['mean']
            cluster_count += 1
        
        avg_brightness = total_brightness / cluster_count if cluster_count > 0 else 0
        avg_confidence = total_confidence / cluster_count if cluster_count > 0 else 0
        
        return f"""## ç«ç½å¼·åº¦åˆ†æ
### Fire Intensity Analysis

#### å¼·åº¦åˆ†é¡çµ±è¨ˆ
- **å…¨ä½“å¹³å‡æ˜åº¦**: {avg_brightness:.1f}K
- **å…¨ä½“å¹³å‡ä¿¡é ¼åº¦**: {avg_confidence:.1f}%

#### å¼·åº¦ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
{chr(10).join([f"- **{category}**: {count}ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼" for category, count in intensity_categories.items()])}

#### ç«ç½å¼·åº¦ã®ç‰¹å¾´

##### é«˜å¼·åº¦ç«ç½ (330K+)
- å¤§è¦æ¨¡ãªæ£®æ—ç«ç½ã‚„å·¥æ¥­ç«ç½ã‚’ç¤ºå”†
- é«˜ã„ç†±æ”¾å°„ã¨æ˜ç¢ºãªç…™ãƒ—ãƒ«ãƒ¼ãƒ 
- ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªãƒ¬ãƒ™ãƒ«

##### ä¸­å¼·åº¦ç«ç½ (310-330K)
- ä¸€èˆ¬çš„ãªé‡ç«ã‚„è¾²æ¥­ç‡ƒç„¼
- ç›£è¦–ãŒå¿…è¦ã ãŒåˆ¶å¾¡å¯èƒ½ãªãƒ¬ãƒ™ãƒ«
- æ‹¡å¤§é˜²æ­¢å¯¾ç­–ã®å®Ÿæ–½æ¨å¥¨

##### ä½å¼·åº¦ç«ç½ (310Kæœªæº€)
- å°è¦æ¨¡ãªç‡ƒç„¼ã‚„æ®‹ã‚Šç«
- å®šæœŸç›£è¦–ã§ååˆ†
- è‡ªç„¶é®ç«ã®å¯èƒ½æ€§

#### åœ°åŸŸåˆ¥å¼·åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³
ç•°ãªã‚‹åœ°åŸŸã§ç‰¹å¾´çš„ãªå¼·åº¦åˆ†å¸ƒã‚’è¦³æ¸¬ã€‚
æ°—å€™æ¡ä»¶ã€æ¤ç”Ÿã‚¿ã‚¤ãƒ—ã€äººé–“æ´»å‹•ã®å½±éŸ¿ãŒå¼·åº¦ã«åæ˜ ã•ã‚Œã¦ã„ã¾ã™ã€‚

---
"""
    
    def _generate_regional_characteristics_section(self, regional_analysis) -> str:
        """åœ°åŸŸç‰¹æ€§åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆåŒ—ç±³åœ°åŸŸå¯¾å¿œï¼‰"""
        
        # å¤šåœ°åŸŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼çµ±è¨ˆ
        multi_regional = sum(1 for data in regional_analysis.values() if data['cross_regional'])
        single_regional = len(regional_analysis) - multi_regional
        
        # åœ°åŸŸå¤šæ§˜æ€§çµ±è¨ˆ
        diversity_scores = [data['region_diversity'] for data in regional_analysis.values()]
        avg_diversity = sum(diversity_scores) / len(diversity_scores) if diversity_scores else 0
        
        return f"""## åœ°åŸŸç‰¹æ€§åˆ†æ
### Regional Characteristics Analysis

#### åœ°åŸŸåˆ†å¸ƒã®ç‰¹å¾´
- **å˜ä¸€åœ°åŸŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼**: {single_regional}å€‹
- **å¤šåœ°åŸŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼**: {multi_regional}å€‹
- **å¹³å‡åœ°åŸŸå¤šæ§˜æ€§**: {avg_diversity:.1f}åœ°åŸŸ/ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼

#### ä¸»è¦åœ°åŸŸã®ç«ç½ç‰¹æ€§

##### ã‚¢ãƒ©ã‚¹ã‚«åœ°åŸŸ
- äºœå¯’å¸¯ã®æ¥µç«¯ãªç«ç½ã‚·ãƒ¼ã‚ºãƒ³
- æ°¸ä¹…å‡åœŸèè§£ã«ã‚ˆã‚‹æ–°ãŸãªãƒªã‚¹ã‚¯
- æ°—å€™å¤‰å‹•ã®å½±éŸ¿ãŒé¡•è‘—

##### è¥¿éƒ¨ã‚«ãƒŠãƒ€åœ°åŸŸ
- å¤ªå¹³æ´‹æ²¿å²¸ã®æ¸©å¸¯é›¨æ—ç«ç½
- ã‚¨ãƒ«ãƒ‹ãƒ¼ãƒ‹ãƒ§ãƒ»ãƒ©ãƒ‹ãƒ¼ãƒ‹ãƒ£ã®å½±éŸ¿
- å±±å²³åœ°å¸¯ã®è¤‡é›‘ãªåœ°å½¢åŠ¹æœ

##### ä¸­å¤®ã‚«ãƒŠãƒ€åœ°åŸŸ
- ãƒ—ãƒ¬ãƒ¼ãƒªãƒ¼è‰åŸã®ç«ç½ç”Ÿæ…‹å­¦
- è¾²æ¥­æ™¯è¦³ã®ç«ç½ç®¡ç†
- å­£ç¯€çš„ãªåˆ¶å¾¡ç‡ƒç„¼

##### æ±éƒ¨ã‚«ãƒŠãƒ€åœ°åŸŸ
- ãƒœãƒªã‚¢ãƒ«æ£®æ—ã®è‡ªç„¶ç«ç½ã‚µã‚¤ã‚¯ãƒ«
- æ¹¿æ½¤æ°—å€™ã«ã‚ˆã‚‹ç«ç½åˆ¶å¾¡
- ç”Ÿç‰©å¤šæ§˜æ€§ä¿å…¨ã¨ã®ä¸¡ç«‹

##### è¥¿éƒ¨ã‚¢ãƒ¡ãƒªã‚«åœ°åŸŸ  
- åœ°ä¸­æµ·æ€§æ°—å€™ã®ç«ç½ãƒªã‚¹ã‚¯
- éƒ½å¸‚æ‹¡å¤§ã¨å±±ç«äº‹å¢ƒç•Œ
- å¹²ã°ã¤ã¨ç«ç½ã®ç›¸äº’ä½œç”¨

##### ã‚¢ãƒ¡ãƒªã‚«ä¸­éƒ¨ãƒ»æ±éƒ¨åœ°åŸŸ
- è¾²æ¥­æ™¯è¦³ã®ç‡ƒç„¼ç®¡ç†
- äººå£å¯†é›†åœ°åŸŸã®ç«ç½å®‰å…¨
- åˆ¶å¾¡ã•ã‚ŒãŸç”Ÿæ…‹ç³»ç®¡ç†

#### è·¨åœ°åŸŸç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³
{multi_regional}å€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãŒè¤‡æ•°åœ°åŸŸã«ã¾ãŸãŒã‚Šã€
å¤§è¦æ¨¡ãªæ°—è±¡ã‚·ã‚¹ãƒ†ãƒ ã‚„äººé–“æ´»å‹•ã®å½±éŸ¿ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚

---
"""
    
    def _generate_visualizations_guide(self) -> str:
        """å¯è¦–åŒ–ã‚¬ã‚¤ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        return f"""## å¯è¦–åŒ–å›³è¡¨ã‚¬ã‚¤ãƒ‰
### Visualization Guide

æœ¬ãƒ¬ãƒãƒ¼ãƒˆã«ã¯ä»¥ä¸‹ã®6ã¤ã®ä¸»è¦å›³è¡¨ãŒå«ã¾ã‚Œã¦ã„ã¾ã™:

#### ğŸ“Š å›³è¡¨1: t-SNE ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¯è¦–åŒ– (`tsne_plot.png`)
- **ç›®çš„**: 20,000ä»¶ã®ç«ç½ãƒ‡ãƒ¼ã‚¿ã®2æ¬¡å…ƒå¯è¦–åŒ–
- **æ‰‹æ³•**: t-SNEæ¬¡å…ƒå‰Šæ¸›ã«ã‚ˆã‚‹384æ¬¡å…ƒâ†’2æ¬¡å…ƒå¤‰æ›
- **è§£é‡ˆ**: é¡ä¼¼ã—ãŸç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¿‘ãã«é…ç½®
- **æ´»ç”¨**: ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼é–“ã®é–¢ä¿‚æ€§ã¨åˆ†é›¢åº¦ã‚’è©•ä¾¡

#### ğŸ“ˆ å›³è¡¨2: ã‚¹ã‚³ã‚¢åˆ†å¸ƒåˆ†æ (`score_distribution.png`)
- **ç›®çš„**: ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥ã®ç‰¹å¾´ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
- **å†…å®¹**: å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®çµ±è¨ˆçš„ç‰¹æ€§
- **è§£é‡ˆ**: ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å†…ã®å‡ä¸€æ€§ã¨é–“ã®å·®ç•°
- **æ´»ç”¨**: ç•°å¸¸å€¤æ¤œå‡ºã¨å“è³ªè©•ä¾¡

#### ğŸ—ºï¸ å›³è¡¨3: åœ°ç†çš„åˆ†å¸ƒãƒãƒƒãƒ— (`cluster_geographic_distribution.png`)
- **ç›®çš„**: ç«ç½ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®åœ°ç†çš„é…ç½®
- **å†…å®¹**: é‡å¿ƒä½ç½®ã€ç¯„å›²ã€å¯†åº¦åˆ†æ
- **è§£é‡ˆ**: åœ°åŸŸåˆ¥ç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å¯è¦–åŒ–
- **æ´»ç”¨**: åœ°ç†çš„ãƒªã‚¹ã‚¯è©•ä¾¡ã¨å¯¾ç­–ç«‹æ¡ˆ

#### ğŸŒ å›³è¡¨4: åœ°åŸŸåˆ†æãƒãƒ£ãƒ¼ãƒˆ (`cluster_regional_analysis.png`)
- **ç›®çš„**: åœ°åŸŸç‰¹æ€§ã¨å¤šæ§˜æ€§åˆ†æ
- **å†…å®¹**: åœ°åŸŸåˆ¥åˆ†å¸ƒã€æ”¯é…çš„åœ°åŸŸã€å¤šæ§˜æ€§æŒ‡æ¨™
- **è§£é‡ˆ**: åœ°åŸŸæ¨ªæ–­çš„ãªç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³
- **æ´»ç”¨**: åœ°åŸŸé–“å”åŠ›ã¨çµ±åˆå¯¾ç­–

#### ğŸ”¥ å›³è¡¨5: ç«ç½å¼·åº¦åˆ†æ (`cluster_intensity_analysis.png`)
- **ç›®çš„**: ç«ç½å¼·åº¦ã®åˆ†å¸ƒã¨ç‰¹æ€§
- **å†…å®¹**: æ˜åº¦ã€ä¿¡é ¼åº¦ã€å¼·åº¦ã‚«ãƒ†ã‚´ãƒª
- **è§£é‡ˆ**: ç«ç½ã®è¦æ¨¡ã¨æ·±åˆ»åº¦è©•ä¾¡
- **æ´»ç”¨**: ç·Šæ€¥å¯¾å¿œã®å„ªå…ˆé †ä½æ±ºå®š

#### â° å›³è¡¨6: æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ (`cluster_temporal_patterns.png`)
- **ç›®çš„**: æ™‚é–“çš„æ´»å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
- **å†…å®¹**: æ™‚é–“åˆ¥ãƒ»æ›œæ—¥åˆ¥ãƒ»ç¶™ç¶šæœŸé–“åˆ†æ
- **è§£é‡ˆ**: ç«ç½æ´»å‹•ã®æ™‚é–“çš„å‚¾å‘
- **æ´»ç”¨**: ç›£è¦–ä½“åˆ¶ã¨äºˆé˜²å¯¾ç­–ã®æœ€é©åŒ–

---
"""
    
    def _generate_conclusions_recommendations(self, cluster_summary) -> str:
        """çµè«–ãƒ»æ¨å¥¨äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆåŒ—ç±³åœ°åŸŸå¯¾å¿œï¼‰"""
        return f"""## çµè«–ã¨æ¨å¥¨äº‹é …
### Conclusions and Recommendations

#### ä¸»è¦ç™ºè¦‹äº‹é …
1. **åœ°ç†çš„ãƒ‘ã‚¿ãƒ¼ãƒ³**: åŒ—ç±³åœ°åŸŸã§{cluster_summary['total_clusters']}ã¤ã®æ˜ç¢ºãªç«ç½ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’ç‰¹å®š
2. **æ™‚é–“çš„å‚¾å‘**: æ˜ç¢ºãªæ—¥å†…ãƒ»é€±å†…ã‚µã‚¤ã‚¯ãƒ«ã‚’ç¢ºèªã€äºˆæ¸¬å¯èƒ½ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç™ºè¦‹
3. **å¼·åº¦åˆ†å¸ƒ**: é«˜ãƒ»ä¸­ãƒ»ä½å¼·åº¦ã®æ˜ç¢ºãªåˆ†é¡ãŒå¯èƒ½ã€ãƒªã‚¹ã‚¯è©•ä¾¡ã«æ´»ç”¨å¯èƒ½
4. **åœ°åŸŸç‰¹æ€§**: å„åœ°åŸŸå›ºæœ‰ã®ç«ç½ç‰¹æ€§ã‚’ç‰¹å®šã€åœ°åŸŸåˆ¥å¯¾ç­–ã®å¿…è¦æ€§ã‚’ç¢ºèª

#### é‹ç”¨ä¸Šã®æ¨å¥¨äº‹é …

##### å³åº§ã®å¯¾å¿œ
- **é«˜å¼·åº¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼**: ç·Šæ€¥ç›£è¦–ä½“åˆ¶ã®å¼·åŒ–
- **å¤šåœ°åŸŸã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼**: ç±³åŠ å›½éš›å”åŠ›ä½“åˆ¶ã®æ§‹ç¯‰
- **æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³**: ãƒ”ãƒ¼ã‚¯æ™‚é–“å¸¯ã®ç›£è¦–å¼·åŒ–

##### ä¸­æœŸçš„æˆ¦ç•¥
- **äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«**: æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ç«ç½äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰
- **æ—©æœŸè­¦æˆ’**: é«˜ãƒªã‚¹ã‚¯åœ°åŸŸã§ã®äºˆé˜²çš„æªç½®
- **è³‡æºé…åˆ†**: ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼è¦æ¨¡ã«å¿œã˜ãŸå¯¾å¿œãƒªã‚½ãƒ¼ã‚¹ã®æœ€é©é…åˆ†

##### é•·æœŸçš„å–çµ„ã¿
- **æ°—å€™å¤‰å‹•å¯¾ç­–**: ç«ç½ãƒ‘ã‚¿ãƒ¼ãƒ³å¤‰åŒ–ã¸ã®é©å¿œæˆ¦ç•¥
- **å›½éš›å”åŠ›**: åŒ—ç±³ç«ç½å¯¾ç­–å”å®šã®å¼·åŒ–
- **æŠ€è¡“é©æ–°**: è¡›æ˜Ÿç›£è¦–æŠ€è¡“ã®ç¶™ç¶šçš„æ”¹å–„

#### åœ°åŸŸåˆ¥é‡ç‚¹å¯¾ç­–

##### ã‚¢ãƒ©ã‚¹ã‚«ãƒ»åŒ—éƒ¨ã‚«ãƒŠãƒ€
- **æ°¸ä¹…å‡åœŸç›£è¦–**: èè§£ã«ã‚ˆã‚‹æ–°ãŸãªç«ç½ãƒªã‚¹ã‚¯è©•ä¾¡
- **æ¥µåœ°å¯¾å¿œ**: æ¥µç«¯æ°—è±¡æ¡ä»¶ä¸‹ã§ã®æ¶ˆç«ä½“åˆ¶
- **å…ˆä½æ°‘å”åŠ›**: ä¼çµ±çš„çŸ¥è­˜ã¨ç¾ä»£æŠ€è¡“ã®èåˆ

##### è¥¿éƒ¨åœ°åŸŸï¼ˆã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢ãƒ»BCå·ï¼‰
- **éƒ½å¸‚å¢ƒç•Œç®¡ç†**: WUIï¼ˆéƒ½å¸‚-æ£®æ—å¢ƒç•Œï¼‰ç«ç½å¯¾ç­–
- **æ°´è³‡æºç®¡ç†**: å¹²ã°ã¤å¯¾å¿œã¨æ¶ˆç«ç”¨æ°´ç¢ºä¿
- **é¿é›£è¨ˆç”»**: å¤§è¦æ¨¡ç«ç½æ™‚ã®ä½æ°‘é¿é›£ä½“åˆ¶

##### ä¸­éƒ¨ãƒ»æ±éƒ¨åœ°åŸŸ
- **è¾²æ¥­ç«ç½ç®¡ç†**: åˆ¶å¾¡ç‡ƒç„¼ã®æœ€é©åŒ–
- **ç”Ÿæ…‹ç³»ä¿å…¨**: ç«ç½ã®ç”Ÿæ…‹å­¦çš„å½¹å‰²ã®æ´»ç”¨
- **éƒ½å¸‚ç«ç½å®‰å…¨**: äººå£å¯†é›†åœ°åŸŸã®äºˆé˜²å¯¾ç­–

#### ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„ææ¡ˆ
- **å‡¦ç†èƒ½åŠ›æ‹¡å¼µ**: ã‚ˆã‚Šå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®å¯¾å¿œ
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒ–**: æº–ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰
- **äºˆæ¸¬æ©Ÿèƒ½**: æ™‚ç³»åˆ—åˆ†æã«ã‚ˆã‚‹ç«ç½äºˆæ¸¬æ©Ÿèƒ½ã®è¿½åŠ 
- **å›½éš›é€£æº**: ã‚«ãƒŠãƒ€ãƒ»ã‚¢ãƒ¡ãƒªã‚«çµ±åˆç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

#### æ¬¡å›åˆ†æã¸ã®æè¨€
- **å­£ç¯€åˆ†æ**: 1å¹´é–“ã®å­£ç¯€å¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æŠŠæ¡
- **è©³ç´°åœ°åŸŸåˆ†æ**: å·ãƒ»çœŒãƒ¬ãƒ™ãƒ«ã§ã®è©³ç´°åˆ†æ
- **åŸå› åˆ†æ**: è‡ªç„¶ç™ºç«ãƒ»äººç‚ºãƒ»è½é›·ã®åˆ†é¡æ©Ÿèƒ½è¿½åŠ 
- **å½±éŸ¿è©•ä¾¡**: çµŒæ¸ˆãƒ»ç’°å¢ƒãƒ»ç¤¾ä¼šã¸ã®å½±éŸ¿åº¦è©•ä¾¡

---

## ä»˜éŒ²
### Appendix

**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')}  
**ã‚·ã‚¹ãƒ†ãƒ **: åŒ—ç±³åœ°åŸŸç«ç½æ¤œçŸ¥åˆ†æã‚·ã‚¹ãƒ†ãƒ  v1.4.3  
**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: NASA FIRMS VIIRS_SNPP_NRT  
**åˆ†æã‚¨ãƒ³ã‚¸ãƒ³**: FAISS k-means + t-SNE + æ©Ÿæ¢°å­¦ç¿’ç‰¹å¾´åˆ†æ  

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹è‡ªå‹•åˆ†æçµæœã§ã™ã€‚
å®Ÿéš›ã®å¯¾å¿œåˆ¤æ–­ã«ã¯å°‚é–€å®¶ã«ã‚ˆã‚‹è©³ç´°ãªæ¤œè¨¼ãŒå¿…è¦ã§ã™ã€‚

---
"""
    
    def _combine_report_sections(self, sections: List[str]) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’çµ±åˆ"""
        return "\n".join(sections)